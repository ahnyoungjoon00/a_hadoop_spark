{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503abec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b998ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a7bed",
   "metadata": {},
   "source": [
    "# 1. DataFrame 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f981045-4dfc-44e5-809a-100de5e5ebe0",
   "metadata": {},
   "source": [
    "### SparkSession.createDataFrame(data, schema=None, samplingRatio=None, verifySchema=True)\n",
    "- data : RDD or iterable\n",
    "- **schema : pyspark.sql.types.DataType, str or list, optional**\n",
    "    - 지정하지 않으면 기본으로 생성해줌\n",
    "- **samplingRatio : the sample ratio of rows used for inferring**\n",
    "    - 스키마가 입력되지 않으면 데이터로 유추해야함, 이때 확인할 데이터 비율\n",
    "        - 인수값이 None이면 전달된 data의 첫번째 data만 읽어 스키마를 유추하게 됨.\n",
    "        - 단, 첫번째 data가 컬렴명이면 유추가 불가능해져서 에러 발생\n",
    "- verifySchema : verify data types of every row against schema. Enabled by default\n",
    "\n",
    "- SparkSession 객체를 사용해 DataFrame을 생성할 수 있다.\n",
    "- SparkSession 객체는 pyspark shell을 실행할 때 spark 라는 이름으로 미리 생성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7852f6",
   "metadata": {},
   "source": [
    "## Row 객체를 사용해 생성하기\n",
    "\n",
    "- row : DataFrame에서의 한 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98186e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1f57b4-bd53-446b-8676-496fbd1c9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cb74f2-d56d-4a70-9476-49c22979fc95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Row'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A row in :class:`DataFrame`.\u001b[0m\n",
       "\u001b[0;34m    The fields in it can be accessed:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    * like attributes (``row.key``)\u001b[0m\n",
       "\u001b[0;34m    * like dictionary values (``row[key]``)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ``key in row`` will search through row keys.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Row can be used to create a row object by using named arguments.\u001b[0m\n",
       "\u001b[0;34m    It is not allowed to omit a named argument to represent that the value is\u001b[0m\n",
       "\u001b[0;34m    None or missing. This should be explicitly set to None in this case.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionchanged:: 3.0.0\u001b[0m\n",
       "\u001b[0;34m        Rows created from named arguments no longer have\u001b[0m\n",
       "\u001b[0;34m        field names sorted alphabetically and will be ordered in the position as\u001b[0m\n",
       "\u001b[0;34m        entered.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from pyspark.sql import Row\u001b[0m\n",
       "\u001b[0;34m    >>> row = Row(name=\"Alice\", age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row\u001b[0m\n",
       "\u001b[0;34m    Row(name='Alice', age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row['name'], row['age']\u001b[0m\n",
       "\u001b[0;34m    ('Alice', 11)\u001b[0m\n",
       "\u001b[0;34m    >>> row.name, row.age\u001b[0m\n",
       "\u001b[0;34m    ('Alice', 11)\u001b[0m\n",
       "\u001b[0;34m    >>> 'name' in row\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> 'wrong_key' in row\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Row also can be used to create another Row like class, then it\u001b[0m\n",
       "\u001b[0;34m    could be used to create Row objects, such as\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> Person = Row(\"name\", \"age\")\u001b[0m\n",
       "\u001b[0;34m    >>> Person\u001b[0m\n",
       "\u001b[0;34m    <Row('name', 'age')>\u001b[0m\n",
       "\u001b[0;34m    >>> 'name' in Person\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> 'wrong_key' in Person\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m    >>> Person(\"Alice\", 11)\u001b[0m\n",
       "\u001b[0;34m    Row(name='Alice', age=11)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This form can also be used to create rows as tuple values, i.e. with unnamed\u001b[0m\n",
       "\u001b[0;34m    fields.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> row1 = Row(\"Alice\", 11)\u001b[0m\n",
       "\u001b[0;34m    >>> row2 = Row(name=\"Alice\", age=11)\u001b[0m\n",
       "\u001b[0;34m    >>> row1 == row2\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mPySparkValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CANNOT_SET_TOGETHER\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"arg_list\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"args and kwargs\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# create row objects\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# create row class or objects\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Return as a dict\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        recursive : bool, optional\u001b[0m\n",
       "\u001b[0;34m            turns the nested Rows to dict (default: False).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        If a row contains duplicate field names, e.g., the rows of a join\u001b[0m\n",
       "\u001b[0;34m        between two :class:`DataFrame` that both have the fields of same names,\u001b[0m\n",
       "\u001b[0;34m        one of the duplicate fields will be selected by ``asDict``. ``__getitem__``\u001b[0m\n",
       "\u001b[0;34m        will also return one of the duplicate fields, however returned value might\u001b[0m\n",
       "\u001b[0;34m        be different to ``asDict``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Examples\u001b[0m\n",
       "\u001b[0;34m        --------\u001b[0m\n",
       "\u001b[0;34m        >>> from pyspark.sql import Row\u001b[0m\n",
       "\u001b[0;34m        >>> Row(name=\"Alice\", age=11).asDict() == {'name': 'Alice', 'age': 11}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        >>> row = Row(key=1, value=Row(name='a', age=2))\u001b[0m\n",
       "\u001b[0;34m        >>> row.asDict() == {'key': 1, 'value': Row(name='a', age=2)}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        >>> row.asDict(True) == {'key': 1, 'value': {'name': 'a', 'age': 2}}\u001b[0m\n",
       "\u001b[0;34m        True\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mPySparkTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CANNOT_CONVERT_TYPE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"from_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"to_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"dict\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mdef\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# let object acts like class\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"create new Row object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mPySparkValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TOO_MANY_VALUES\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"expected\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"item\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"fields\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"actual\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0m_create_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# it will be slow when it has many fields,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# but this will not be used in normal cases\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mPySparkValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# it will be slow when it has many fields,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# but this will not be used in normal cases\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Row is read-only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Returns a tuple so Python knows how to pickle Row.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_create_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Printable representation of Row used in Python REPL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__fields__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Row(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"%s=%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<Row(%s)>\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/spark/python/pyspark/sql/types.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Spark.Row 클래스\n",
    "??Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48144bd-b282-4432-a437-79ea3c78ce76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='김철수', age=15, birth=datetime.date(2011, 7, 22))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'김철수'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.Row는 명명된 인수를 사용하여 행 개체를 만드는 데 사용할 수 있음\n",
    "row = Row(name=\"김철수\", age=15, birth=date(2011, 7, 22))\n",
    "row\n",
    "row[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bae44ea-7db9-4ff7-8d4f-181bdfabb924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint, birth: date]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|2011-07-22|\n",
      "|이제동| 17|2009-01-01|\n",
      "|김명운| 19|2007-11-30|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark DF 생성\n",
    "# row class 의 생성자로 keyword args를 선달해서 생성\n",
    "df = spark.createDataFrame([\n",
    "    Row(name=\"김철수\", age=15, birth=date(2011, 7, 22)),\n",
    "    Row(name=\"이제동\", age=17, birth=date(2009, 1, 1)),\n",
    "    Row(name=\"김명운\", age=19, birth=date(2007, 11, 30))\n",
    "])\n",
    "df\n",
    "# 출력 결과 : DataFrame[name: string, age: bigint, birth: date] \n",
    "# --> 지연연산되면서 스키마(기본 구조 : 컬럼명:데이터타입)\n",
    "\n",
    "df.show()\n",
    "# 출력결과\n",
    "# +------+---+----------+\n",
    "# |  name|age|     birth|\n",
    "# +------+---+----------+\n",
    "# |김철수| 15|2011-07-22|\n",
    "# |이제동| 17|2009-01-01|\n",
    "# |김명운| 19|2007-11-30|\n",
    "# +------+---+----------+\n",
    "# df 확인 : action을 진행해야함 --> show(n) : n개의 행만큼만 출력, n 기본값 20개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0faa103-f945-4d30-9a78-ed36ccbd8930",
   "metadata": {},
   "source": [
    "- 논리적 연산 계획을 최적화하기 위해 schema 사용\n",
    "- 지정하지 않으면 자동생성\n",
    "- 전체 스키마 확인\n",
    "    - df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb710e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- birth: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스키마(구조) 확인 - 자동 생성된(data를 보고 spark가 유추해놓은)\n",
    "# + null 허용 여부까지 // 대부분 허용하게 됨\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54c584",
   "metadata": {},
   "source": [
    "## schema를 명시하여 DataFrame 생성\n",
    "- 사용자 명시 스키마 활용\n",
    "- schema 인수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2295388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|2011-07-22|\n",
      "|이제동| 17|2009-01-01|\n",
      "|김명운| 19|2007-11-30|\n",
      "+------+---+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- birth: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 튜플에 데이터를 저장하고 스키마(pands df의 column)를 직접 지정\n",
    "df2 = spark.createDataFrame([\n",
    "    Row(name=\"김철수\", age=15, birth=date(2011, 7, 22)),\n",
    "    Row(name=\"이제동\", age=17, birth=date(2009, 1, 1)),\n",
    "    Row(name=\"김명운\", age=19, birth=date(2007, 11, 30))\n",
    "], schema='name string, age int, birth date')\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523fee7a",
   "metadata": {},
   "source": [
    "## StructType 객체를 사용해 Schema 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec49fd94-a270-4afb-8951-2aea1346d5b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataType\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnullable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A field in :class:`StructType`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    name : str\u001b[0m\n",
       "\u001b[0;34m        name of the field.\u001b[0m\n",
       "\u001b[0;34m    dataType : :class:`DataType`\u001b[0m\n",
       "\u001b[0;34m        :class:`DataType` of the field.\u001b[0m\n",
       "\u001b[0;34m    nullable : bool, optional\u001b[0m\n",
       "\u001b[0;34m        whether the field can be null (None) or not.\u001b[0m\n",
       "\u001b[0;34m    metadata : dict, optional\u001b[0m\n",
       "\u001b[0;34m        a dict from string to simple type that can be toInternald to JSON automatically\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from pyspark.sql.types import StringType, StructField\u001b[0m\n",
       "\u001b[0;34m    >>> (StructField(\"f1\", StringType(), True)\u001b[0m\n",
       "\u001b[0;34m    ...      == StructField(\"f1\", StringType(), True))\u001b[0m\n",
       "\u001b[0;34m    True\u001b[0m\n",
       "\u001b[0;34m    >>> (StructField(\"f1\", StringType(), True)\u001b[0m\n",
       "\u001b[0;34m    ...      == StructField(\"f2\", StringType(), True))\u001b[0m\n",
       "\u001b[0;34m    False\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdataType\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnullable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataType %s should be an instance of %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mDataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"field name %s should be a string\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msimpleString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimpleString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"StructField('%s', %s, %s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mjsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsonValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"nullable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"StructField\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_parse_datatype_json_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nullable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mneedConversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneedConversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtoInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfromInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtypeName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[override]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mPySparkTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"INVALID_TYPENAME_CALL\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/spark/python/pyspark/sql/types.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ddecd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e3e543a-d88b-4f0a-bce3-578fe752cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructField(name: ,dataType: ,nullable: bool = True, metadata: None)\n",
    "# df의 열별로 structFiled를 구성\n",
    "# 컬럼 type은 XXXType() 사용 : StringType(), IntegerType()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"age\", IntegerType(), False),\n",
    "    StructField(\"birth\", DateType(), False),\n",
    "])\n",
    "data = [\n",
    "    (\"김철수\", 15, date(2011, 7, 22)),\n",
    "    # (\"\", 15, date(2011, 7, 22)),\n",
    "    # 빈문자열은 null과 다르기때문에 error없이 수행 가능\n",
    "    (\"이제동\", 17, date(2009, 1, 1)),\n",
    "    # (\"이제동\", \"\", date(2009, 1, 1)),\n",
    "    # PySparkTypeError: [CANNOT_ACCEPT_OBJECT_IN_TYPE] `IntegerType()` can not accept object `` in type `str`.\n",
    "    (\"김명운\", 19, date(2007, 11, 30)),\n",
    "    # (\"김명운\", 19, None),\n",
    "    # PySparkValueError: [CANNOT_BE_NONE] Argument `obj` can not be None.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bc6b4e8-352d-458b-a924-17d119fce0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      "\n",
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 15|2011-07-22|\n",
      "|이제동| 17|2009-01-01|\n",
      "|김명운| 19|2007-11-30|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data=data, schema=schema)\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0399d3a",
   "metadata": {},
   "source": [
    "## 중첩스키마적용\n",
    "- 컬럼의 데이터가 단일 데이터가 아닌 iter 데이터일 경우\n",
    "- -스키마를 컬럼의 원소값 각각에 대해 생성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dfdd27c-2a44-44d4-b9e7-d8aa947d963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('김철수', 15, date(2022,7,22), ('010','1111','2222')),\n",
    "    ('이제동', 20, date(2021,7,22), ('010','2222','3333')),\n",
    "    ('김명운', 25, date(2020,7,22), ('010','4444','5555'))\n",
    "]\n",
    "# StructField(name, dataType, nullable=True, metadata=None)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name',StringType(), False, {\"desc\":\"이름\"}), # name 컬럼 null 불허\n",
    "    StructField('age',IntegerType(), False, {\"desc\":\"나이\"}),\n",
    "    StructField('birth',DateType(), False, {\"desc\":\"생일\"}),\n",
    "    StructField('phone',StructType([\n",
    "        StructField(\"phone1\", StringType(), True),\n",
    "        StructField(\"phone2\", StringType(), True),\n",
    "        StructField(\"phone3\", StringType(), True)\n",
    "    ]), False, {\"desc\":\"전화번호\"}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06006dbf-07d3-4847-b7a0-6492bb32ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f181241-2a19-42b5-a804-cd476b05dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      " |-- phone: struct (nullable = false)\n",
      " |    |-- phone1: string (nullable = true)\n",
      " |    |-- phone2: string (nullable = true)\n",
      " |    |-- phone3: string (nullable = true)\n",
      "\n",
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "+------+---+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b088aa-a644-47fd-bd7c-bcfe4254025c",
   "metadata": {},
   "source": [
    "#### schema 접근\n",
    "    - df.schema\n",
    "    - 주로 json() 이용해서 json으로 변환 후, 저장하는 방식을 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85b8bfe7-d110-420a-a7d5-31c8c7313531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StringType(), False), StructField('age', IntegerType(), False), StructField('birth', DateType(), False), StructField('phone', StructType([StructField('phone1', StringType(), True), StructField('phone2', StringType(), True), StructField('phone3', StringType(), True)]), False)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "{\"fields\":[{\"metadata\":{\"desc\":\"\\uc774\\ub984\"},\"name\":\"name\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{\"desc\":\"\\ub098\\uc774\"},\"name\":\"age\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{\"desc\":\"\\uc0dd\\uc77c\"},\"name\":\"birth\",\"nullable\":false,\"type\":\"date\"},{\"metadata\":{\"desc\":\"\\uc804\\ud654\\ubc88\\ud638\"},\"name\":\"phone\",\"nullable\":false,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"phone1\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone2\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone3\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}\n",
      "-----------------------------------------------------\n",
      "{\"fields\":[{\"metadata\":{\"desc\":\"이름\"},\"name\":\"name\",\"nullable\":false,\"type\":\"string\"},{\"metadata\":{\"desc\":\"나이\"},\"name\":\"age\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{\"desc\":\"생일\"},\"name\":\"birth\",\"nullable\":false,\"type\":\"date\"},{\"metadata\":{\"desc\":\"전화번호\"},\"name\":\"phone\",\"nullable\":false,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"phone1\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone2\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"phone3\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}\n"
     ]
    }
   ],
   "source": [
    "# 스키마를 json으로 변환하여 확인\n",
    "df4.schema\n",
    "print('-----------------------------------------------------')\n",
    "# 이름 => \\uc774\\ub984  유니코드로 나온다. 한글인식문제\n",
    "df4_json = df4.schema.json()\n",
    "print(df4_json)\n",
    "print('-----------------------------------------------------')\n",
    "# encode() 로 바이트문자(코드)로 변환한 후,\n",
    "# decode() 로 다시 디코딩할때 바로 볼 수 있도록 unicode_escape 옵션 추가\n",
    "print(df4_json.encode().decode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "241c61d4-a20e-4810-b61a-5270ec1c52a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('age', 'int'),\n",
       " ('birth', 'date'),\n",
       " ('phone', 'struct<phone1:string,phone2:string,phone3:string>')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- spark.df의 각 컬럼 data type 확인의 경우\n",
    "#   - pandas.DataFrame과 같이 df.dtypes 로 확인 \n",
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8485e30",
   "metadata": {},
   "source": [
    "## Pandas DataFrame으로 생성\n",
    "- pd.DataFrame을 spark DataFrame으로 변환\n",
    "- spark.createDataFrame(pd.DF) 이렇게 넘겨주는 방식\n",
    "    - 데이터 프레임 자체를 그냥 넘기는게 아니라\n",
    "    - pd.DataFrame.**iteritems** 속성값을 전달해야 함\n",
    "        - pd.iteritems는 pd.DataFrame의 items라는 속성에 값이 들어 있음\n",
    "            - 현재 판다스 버전에서 변경사항이 있어서 구글링해서 찾으면 과거 코드만 나와버리는 중\n",
    "        - 그래서 pd.DataFrame.iteritems = pd.DataFrame.items 이렇게 불러다가 저장해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9d69318-f98a-4248-b8ee-f8ae34f3c515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김철수</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이제동</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김명운</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  age       birth\n",
       "0  김철수   20  2022-07-01\n",
       "1  이제동   21  2022-07-02\n",
       "2  김명운   22  2022-07-03"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = pd.DataFrame({\n",
    "    'name':['김철수','이제동','김명운'],\n",
    "    'age':[20, 21, 22],\n",
    "    'birth':[date(2022,7,1),date(2022,7,2),date(2022,7,3)]\n",
    "})\n",
    "\n",
    "type(pandas_df)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "269cd4d8-9239-4d4f-a703-d6d8d46faea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pandas 2.0 버전 이상부터 iteritems atrr이 items로 변경됨\n",
    "# sprk.createDataFrame은 pd.DataFrame.iteritems를 사용하므로 변경 반영 후 사용해야 함\n",
    "# pandas에 저장되어 있는 속성값을 직접 설정하는 코드\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edd19d6b-d98b-484b-b13b-f06a330188d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint, birth: date]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  name|age|     birth|\n",
      "+------+---+----------+\n",
      "|김철수| 20|2022-07-01|\n",
      "|이제동| 21|2022-07-02|\n",
      "|김명운| 22|2022-07-03|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pd_sp = spark.createDataFrame(pandas_df)\n",
    "df_pd_sp\n",
    "df_pd_sp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec6a6f",
   "metadata": {},
   "source": [
    "## spark.DataFrame -> Pandas.DataFrame\n",
    "- 스파크의 DataFrame을 사용하는 것이 성능상 더 이득\n",
    "- 스파크는 병렬처리도 해주고... 쿼리실행 최적화도 해주고...\n",
    "- =============================================================\n",
    "- 하지만 스파크 api가 Pandas에 비해 제공되는 기능(module)이 적어서\n",
    "- Pandas를 써야만 해결이 가능하다면 Pandas로 가공 이후 스파크 DataFrame으로 변환도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729990c",
   "metadata": {},
   "source": [
    "## spark.DataFrame -> pandas.DataFrame\n",
    "- sparkDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5949244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김철수</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이제동</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김명운</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  age       birth\n",
       "0  김철수   20  2022-07-01\n",
       "1  이제동   21  2022-07-02\n",
       "2  김명운   22  2022-07-03"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_sp= df_pd_sp.toPandas()\n",
    "df_pd_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4045214-96b0-411d-9bda-31913770db78",
   "metadata": {},
   "source": [
    "## pandas.DataFrame -> spark.DataFrame\n",
    "- pandasDF.to_pandas_on_spark()\n",
    "    - pyarrow timezone을 무시하도록 변경\n",
    "    - numpy 2.0 이상 버전에서는 에러 발생\n",
    "    - 쓰려면 numpy 2.0 미만으로 downgrade 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14d89028-ca79-458b-9855-99c7f142aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb79110a-d9a0-4669-a0bd-ecd02a917144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip uninstall numpy -y\n",
    "# !pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7304ee8-23c6-4aef-85e4-f57e39d80077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b7d832a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_pandas_on_spark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1465/1512090518.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 대체로 sparkDF -> pandasDF 이런식으로 바꿔서 데이터 처리하는데\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# sparkDF -> pysparkDF 이 상태에서 데이터를 처리하는 것이 더 좋을때가 있어서\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 지금 numpy 2.0미만으로 다운그레이드해서 아래의 모듈들을 써보려는 과정임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 모듈이 오래됨, pyspark df를 활용가능한 모듈이기때문에\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_pd_sp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas_on_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_pandas_on_spark'"
     ]
    }
   ],
   "source": [
    "# sparkDF -> pysparkDF -> pandasDF 이렇게 구성이 있는데\n",
    "# 대체로 sparkDF -> pandasDF 이런식으로 바꿔서 데이터 처리하는데\n",
    "# sparkDF -> pysparkDF 이 상태에서 데이터를 처리하는 것이 더 좋을때가 있어서 \n",
    "# 지금 numpy 2.0미만으로 다운그레이드해서 아래의 모듈들을 써보려는 과정임\n",
    "\n",
    "# 모듈이 오래됨, pyspark df를 활용가능한 모듈이기때문에 파이프라인 ETL위래서 모듈 사용가능한 상황으로 구성\n",
    "df_pd_sp.to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba3fc1",
   "metadata": {},
   "source": [
    "## 외부파일을 사용해 DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed5830f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|class_cd|school|class_std_cnt|     loc|school_type|teaching_type|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "|     6OL| ANKYI|           20|   Urban| Non-public|     Standard|\n",
      "|     ZNS| ANKYI|           21|   Urban| Non-public|     Standard|\n",
      "|     2B1| CCAAW|           18|Suburban| Non-public| Experimental|\n",
      "+--------+------+-------------+--------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_df = spark.read.csv('/dataframe/a_class_info.csv', header = True)\n",
    "type(class_df)\n",
    "class_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c47bf-da39-493c-88ba-bbb3f9354223",
   "metadata": {},
   "source": [
    "### pyspark.sql.dataframe.DataFrame show()\n",
    "- def show( : 20개의 행을 표시)\n",
    "- def show(numRows : scala.Int) : 정해진 수 만큼 행 표시\n",
    "- def show(truncate : scala.Boolean) : 열값이 길어 모두 표현되지 않을경우 표현 여부\n",
    "    - truncate : True -> 열값을 자르고 표시 / False -> 열값을 모두 표시\n",
    "- def show(numRows : scala.Int, truncate : scala.Boolean) : 표현할 행과 열값을 자를것인지의 여부\n",
    "- def show(numRows : scala.Int, truncate : scala.Int ) : 표현할 행과 열값을 몇 글자 보여줄 것인지 여\n",
    "- def show(numRows : scala.Int, truncate : scala.Int, vertical : scala.Boolean) : 레코드별로 세로로 표시할 \n",
    "- 모든 행을 표현하고자 한다면\n",
    "    - count()사용해 행 수를 얻어와서 show()로 연결해야 함\n",
    "    - def show(df.count())것인지의 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65c5ef88-9ddb-4697-8e8e-0e7a67acf624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------\n",
      " class_cd      | 6OL        \n",
      " school        | ANKYI      \n",
      " class_std_cnt | 20         \n",
      " loc           | Urban      \n",
      " school_type   | Non-public \n",
      " teaching_type | Standard   \n",
      "-RECORD 1-------------------\n",
      " class_cd      | ZNS        \n",
      " school        | ANKYI      \n",
      " class_std_cnt | 21         \n",
      " loc           | Urban      \n",
      " school_type   | Non-public \n",
      " teaching_type | Standard   \n",
      "only showing top 2 rows\n",
      "\n",
      "-RECORD 0-------------------\n",
      " class_cd      | 6OL        \n",
      " school        | ANKYI      \n",
      " class_std_cnt | 20         \n",
      " loc           | Urban      \n",
      " school_type   | Non-public \n",
      " teaching_type | Standard   \n",
      "-RECORD 1-------------------\n",
      " class_cd      | ZNS        \n",
      " school        | ANKYI      \n",
      " class_std_cnt | 21         \n",
      " loc           | Urban      \n",
      " school_type   | Non-public \n",
      " teaching_type | Standard   \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_df.show()\n",
    "class_df.count() # action 메소드 이다\n",
    "# class_df.show(1)\n",
    "# class_df.show(2, truncate=2) # truncate : 각 열별 값을 몇글자 표현할 것인가 \n",
    "# class_df.show(2, truncate=False) # 각 열의 값이 잘리는 것을 방지하겠다\n",
    "\n",
    "class_df.show(2, vertical=True) # 각 행별로  \n",
    "type(class_df.show(2, vertical=True)) # NoneType : collect() 같은 경우 출력후 list 반환인, show() 반환값없이 보여주기만 함\n",
    "\n",
    "# 이 코드는 모든 node data 순회해서 결과 반환하므로 성능이 떨어지게 됨, action method + action method\n",
    "# 사용할 일이 자주 있다면 메모리에 상주시켜 사용하는 것이 성능 측면에서 좋다\n",
    "# class_df.show(class_df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb39b6",
   "metadata": {},
   "source": [
    "## pyspark.sql.dataframe.DataFrame\n",
    "\n",
    "- withColumn('컬럼명', '값')\n",
    "    - 지연연산 모듈\n",
    "    - 연산계획에 참여함\n",
    "- 기존 컬럼 업데이트, 타입 변경, 신규컬럼 추가 기능\n",
    "- 신규 또는 업데이트 값 줄때 주의\n",
    "    - 신규컬럼 값 타입 활용, 업데이트 진행시, 기존 컬럼 값 활용 : col(\"컬럼명\") -> 기존 컬럼의 값 참조 가능\n",
    "\n",
    "- withColumnRenamed()\n",
    "    - 컬럼명 변경 연산의 메소드\n",
    "\n",
    "- spark의 lit function\n",
    "    - 모든 타입을 허용하는 함수\n",
    "    - 어떤 타입이 들어와도 객체로 인식하고 연산 진행시, 원하는 타입(유추타입)으로 변환 가능\n",
    "    - 지연연산을 진행하므로 추가되는 컬럼값에 대해 타입 바로 결정 불가능, lit() 이용 객체 등록 후, 최적화 시, 타입 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096328b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    ('김철수', 15, date(2022,7,22), ('010','1111','2222')),\n",
    "    ('이제동', 20, date(2021,7,22), ('010','2222','3333')),\n",
    "    ('김명운', 25, date(2020,7,22), ('010','4444','5555')),\n",
    "    ('홍진호', 36, date(2018,7,22), ('010','3333','4444'))\n",
    "]\n",
    "schema = StructType([\n",
    "    StructField('name',StringType(),False,{'desc':'이름'}),\n",
    "    StructField('age',IntegerType(),False,{'desc':'나이'}),    \n",
    "    StructField('birth',DateType(),False,{'desc' :'생일'}),\n",
    "    StructField('phone', StructType([\n",
    "        StructField('phone1',StringType(),True),\n",
    "        StructField('phone2',StringType(),True),\n",
    "        StructField('phone3',StringType(),True)]),False,{'desc':'전화번호'}) # 중첩스키마\n",
    "])\n",
    "col_df = spark.createDataFrame(data, schema=schema)\n",
    "type(col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be8a2250-8a51-4695-be42-93a7383f7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "+------+---+----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8801994b-f58f-40c4-a1e9-f4ea6ac9a134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+--------+\n",
      "|  name|age|     birth|            phone|우승여부|\n",
      "+------+---+----------+-----------------+--------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|        |\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|        |\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|        |\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|        |\n",
      "+------+---+----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn : 컬럼이름, 컬럼\n",
    "# lit : column 객체를 literal로 만들어주는 함수\n",
    "# 원하는 컬럼을 DataFrame에 추가\n",
    "# col_df.withColumn('우승여부', '').show() # 이렇게 lit()으로 인지시켜주지 않으면 유추 자체가 불가능해짐\n",
    "tmp = col_df.withColumn('우승여부', lit('')) # 그냥 객체가 있다 라고만 알려줘도 알아서 유추해줌\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25a5a635-9979-4d96-aaf5-52f9c77c8245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|\n",
      "+------+---+----------+-----------------+\n",
      "\n",
      "+------+---+----------+-----------------+--------+\n",
      "|  name|age|     birth|            phone|우승여부|\n",
      "+------+---+----------+-----------------+--------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|    우승|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|    우승|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|    우승|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|    우승|\n",
      "+------+---+----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 값을 지정해서 추가\n",
    "col_df.show()\n",
    "col_df.withColumn(\"우승여부\", lit(\"우승\")).show() # 객체도 이렇게 lit()으로 인지시켜주지 않으면 유추 자체가 불가능해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5847ef-65ac-430e-9843-42c939a69c43",
   "metadata": {},
   "source": [
    "### 파생컬럼 생성\n",
    "- 기존 컬럼값을 가공해서 새로운 컬럼을 추가\n",
    "- age 컬럼값에 따라 연령대라는 컬럼을 추가\n",
    "- spark 의 sql.dataframe에서 \n",
    "    - if문처럼 사용할 수 있는 SQL function인 case-when과 비슷한\n",
    "        - when( + otherwise)을 사용 가능\n",
    "        - when(조건1, 조건1이 참일때 값).when(조건2, 조건2가 참일때).otherwise(그 외 모든 경우 값)\n",
    "        - 조건1이 참이면 마감, 거짓이면 --> 조건2가 참인지, 거짓이면 --> otherwise 까지\n",
    "        - if - elif - else "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f110eada-4fee-41e8-9360-c2210ba2b563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- birth: date (nullable = false)\n",
      " |-- phone: struct (nullable = false)\n",
      " |    |-- phone1: string (nullable = true)\n",
      " |    |-- phone2: string (nullable = true)\n",
      " |    |-- phone3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when - otherwise : 조건에 따라 원하는 컬럼객체를 반환\n",
    "col_df.age\n",
    "col_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b36e25",
   "metadata": {},
   "source": [
    "### column  내용  변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07f30739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|   연령대|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when - otherwise : 조건에 따라 원하는 컬럼객체를 반환\n",
    "# 확인사항\n",
    "# col_df.age => column<'age'> column 객체와 연산이 가능한지 O \n",
    "# 같은 것 col(\"age\") == col_df.age == column(\"age\")\n",
    "# 정수 / 정수 = 정수의 결과값을 내놓는지  X // 15/10 이 실수인 1.5(정수가 X) \n",
    "# --> 버림으로 정수가 되도록 조치 결과값에 floor() 적용\n",
    "\n",
    "tmp = col_df.withColumn(\"연령대\", when(floor(col_df.age/10)==1, \"10대\") \n",
    "                                .when(floor(col_df.age/10)==2, \"20대\")\n",
    "                                .otherwise(\"30대 이상\"))\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5c51f14-ec2c-48f7-ab38-1a27739d98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|   연령대|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n",
      "+------+---+----------+-----------------+------+\n",
      "|  name|age|     birth|            phone|연령대|\n",
      "+------+---+----------+-----------------+------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|청소년|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|  청년|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|  청년|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|  성인|\n",
      "+------+---+----------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기존 컬럼인 연령대의 값을 변경\n",
    "tmp.show()\n",
    "# tmp.withColumn(\"연령대\", when(floor(col(\"age\")/10)==1, \"청소년\")\n",
    "#                        .when(floor(col(\"age\")/10)==2, \"청년\")\n",
    "#                        .otherwise(\"성인\")).show()\n",
    "tmp.withColumn(\"연령대\", when(floor(col_df.age/10)==1, \"청소년\")\n",
    "                       .when(floor(col_df.age/10)==2, \"청년\")\n",
    "                       .otherwise(\"성인\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4ae4f",
   "metadata": {},
   "source": [
    "### column 이름 변경\n",
    "- withColumnRenamed(\"변경 전 컬럼명\", \"변경 후 컬럼명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7337f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|     분류|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.withColumnRenamed(\"연령대\", \"분류\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b939",
   "metadata": {},
   "source": [
    "### column  삭제 연산 계획\n",
    "- spark.sql.df.drop(\"컬럼명\")\n",
    "- 해당 컬럼이 없어도 연산 처리 시(action), 에러가 발생하지 않고 넘어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4f1ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+---------+\n",
      "|  name|age|     birth|            phone|   연령대|\n",
      "+------+---+----------+-----------------+---------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|     10대|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|     20대|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|     20대|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|30대 이상|\n",
      "+------+---+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = tmp.drop(\"분류\") \n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "129d7c39-8390-488b-9c54-4012fcf504d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------+\n",
      "|  name|age|     birth|            phone|\n",
      "+------+---+----------+-----------------+\n",
      "|김철수| 15|2022-07-22|{010, 1111, 2222}|\n",
      "|이제동| 20|2021-07-22|{010, 2222, 3333}|\n",
      "|김명운| 25|2020-07-22|{010, 4444, 5555}|\n",
      "|홍진호| 36|2018-07-22|{010, 3333, 4444}|\n",
      "+------+---+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = tmp.withColumnRenamed(\"연령대\", \"분류\")\n",
    "tmp = tmp.drop(\"분류\") \n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedcf61",
   "metadata": {},
   "source": [
    "# 2. DataFrame 사용 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533d543",
   "metadata": {},
   "source": [
    "참고 : https://spark.apache.org/docs/3.2.0/api/scala/org/apache/spark/sql/Dataset.html \n",
    "\n",
    "- DataFrame의 메서드의 구분\n",
    " - transformation\n",
    " - action\n",
    " - Basic Dataset functions  \n",
    " \n",
    " \n",
    "- DataFrame의 사용은 SQL 쿼리 구조를 따라간다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
