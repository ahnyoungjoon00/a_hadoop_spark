{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50d6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python을 이용 hadoop file system을 다루는 모듈 패키지(원래 명령어로 하던 것들)\n",
    "# !pip install hdfs\n",
    "# ref : https://hdfscli.readthedocs.io/en/latest/quickstart.html#python-bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811fbbff-637d-4cba-b56f-326f375ed9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d45deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cba7e6-40b9-47fb-80a3-90630249b73e",
   "metadata": {},
   "source": [
    "## hdfs 사용 클라이언트 객체 생성\n",
    "- hdfs 연결 담당\n",
    "- read/write/append/update 등과 관련되 모듈 포함하고 있음\n",
    "- InsecureClient(\"연결주소\", user = \"사용자)\n",
    "- 파일 읽기\n",
    "    - InsecureClient.read(파일명(파일경로 포함))\n",
    "        - 해당 파일을 읽을 수 있는 reader 객체를 반환\n",
    "    - InsecureClient.write(저장할 파일명(파일경로 포함))\n",
    "        - 해당 파일을 읽을 수 있는 writer 객체를 반환\n",
    "    - InsecureClient.write(저장할 파일명(파일경로 포함), \"추가될 내용\", append= True)\n",
    "        - 기존파일에 추가될 내용을 append() : 파일 끝에 쓰기\n",
    "     \n",
    "    - InsecureClient.upload(hdfs에 복사될 파일명(경로포함), 원본 폴더명(경로포함))\n",
    "        - 지정된 원본 폴더 파일을 저장할 hdfd 폴더에 복사\n",
    "        - 폴더를 생성하고 시작 : 기존에 동일 이름의 폴더가 있으면 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80285bcd-810f-423a-8706-09cbfaab3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9870port : name node 연결 port \n",
    "# 9000port : data node(hdfs) 연결 port\n",
    "client = InsecureClient(\"http://localhost:9870\", user=\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712a763",
   "metadata": {},
   "source": [
    "## hdfs로 부터 읽기\n",
    "- 파일과 연결(open)\n",
    "- 읽기\n",
    "- 파일 연결 끊기(close) : 개발자가 close해줘야 자원 정리됨 // 까먹거나 그런경우 자주 발생\n",
    "    - with문을 사용하면 자동으로 open ~ close가 진행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e12480-c1fe-45cd-bd6a-62d4ff0aeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기 위한 reader 객체 생성 후 진행\n",
    "with client.read(\"/rdd/score.txt\") as reader :\n",
    "    score = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6e7c94-bb95-4248-9d72-8ea3cdd0c51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xea\\xb9\\x80\\xec\\xb2\\xa0\\xec\\x88\\x98 \\xec\\x8a\\xa4\\xed\\x8c\\x8c\\xed\\x81\\xac 50\\r\\n\\xed\\x99\\x8d\\xea\\xb8\\xb8\\xeb\\x8f\\x99 \\xec\\x8a\\xa4\\xed\\x8c\\x8c\\xed\\x81\\xac 80\\r\\n\\xec\\x9e\\x84\\xea\\xba\\xbd\\xec\\xa0\\x95 \\xec\\x8a\\xa4\\xed\\x8c\\x8c\\xed\\x81\\xac 60\\r\\n\\xec\\x9e\\x84\\xec\\x9a\\x94\\xed\\x99\\x98 \\xed\\x85\\x90\\xec\\x84\\x9c\\xed\\x94\\x8c\\xeb\\xa1\\x9c\\xec\\x9a\\xb0 100\\r\\n\\xed\\x99\\x8d\\xec\\xa7\\x84\\xed\\x98\\xb8 \\xed\\x85\\x90\\xec\\x84\\x9c\\xed\\x94\\x8c\\xeb\\xa1\\x9c\\xec\\x9a\\xb0 22\\r\\n\\xed\\x99\\x8d\\xec\\xa7\\x84\\xed\\x98\\xb8 \\xed\\x85\\x90\\xec\\x84\\x9c\\xed\\x94\\x8c\\xeb\\xa1\\x9c\\xec\\x9a\\xb0 22\\r\\n\\xec\\x9d\\xb4\\xec\\x9c\\xa4\\xec\\x97\\xb4 \\xed\\x85\\x90\\xec\\x84\\x9c\\xed\\x94\\x8c\\xeb\\xa1\\x9c\\xec\\x9a\\xb0 90\\r\\n\\xec\\xb5\\x9c\\xec\\x97\\xb0\\xec\\x84\\xb1 \\xec\\x9e\\xa5\\xea\\xb3\\xa0 100\\xec\\xb5\\x9c\\xec\\x97\\xb0\\xec\\x84\\xb1 \\xec\\x9e\\xa5\\xea\\xb3\\xa0 100\\xec\\xb5\\x9c\\xec\\x97\\xb0\\xec\\x84\\xb1 \\xec\\x9e\\xa5\\xea\\xb3\\xa0 100\\xec\\xb5\\x9c\\xec\\x97\\xb0\\xec\\x84\\xb1 \\xec\\x9e\\xa5\\xea\\xb3\\xa0 100'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# byte code 읽어옴\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890bb35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수 스파크 50\n",
      "홍길동 스파크 80\n",
      "임꺽정 스파크 60\n",
      "임요환 텐서플로우 100\n",
      "홍진호 텐서플로우 22\n",
      "홍진호 텐서플로우 22\n",
      "이윤열 텐서플로우 90\n",
      "최연성 장고 100최연성 장고 100최연성 장고 100최연성 장고 100\n"
     ]
    }
   ],
   "source": [
    "# https://docs.python.org/ko/3/library/stdtypes.html#bytes-and-bytearray-operations\n",
    "# byte code decode해서 저장 후 확인\n",
    "# bytes.decode(data)\n",
    "score_data = bytes.decode(score)\n",
    "print(score_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef087e",
   "metadata": {},
   "source": [
    "## hdfs에 쓰기\n",
    "- hdd(note 디렉터리)에 잇는 data(file)를 hdfs로 복사\n",
    "1. 로컬 데이터 파일 열기 : open() python method 사용, with 등록\n",
    "2. hdfs client 통해서 쓰기 객체 with 등록\n",
    "3. open 객체 이용해서 한줄씩 읽어서 -> hdfs에 쓰기\n",
    "- 현재 위치 : /root/note/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458c67df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "HdfsError",
     "evalue": "/corona_data/sido_area_tmp.csv for client 127.0.0.1 already exists\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:388)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2819)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2713)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:830)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:504)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:3203)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHdfsError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/corona_data/sido_area.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCP949\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader, client\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/corona_data/sido_area_tmp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer :\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m reader: \u001b[38;5;66;03m# 읽어와서\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite(line\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCP949\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m# 원래 encoding 방식을 유지 시켜야함, 바로쓰기\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdfs/util.py:104\u001b[0m, in \u001b[0;36mAsyncWriter.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_err:\n\u001b[0;32m--> 104\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_err \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChild terminated without errors.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdfs/util.py:76\u001b[0m, in \u001b[0;36mAsyncWriter.__enter__.<locals>.consumer\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m   _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting consumer.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consumer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     78\u001b[0m   _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mException in child.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdfs/client.py:515\u001b[0m, in \u001b[0;36mClient.write.<locals>.consumer\u001b[0;34m(_data)\u001b[0m\n\u001b[1;32m    509\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    510\u001b[0m   method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m append \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    511\u001b[0m   url\u001b[38;5;241m=\u001b[39mloc,\n\u001b[1;32m    512\u001b[0m   data\u001b[38;5;241m=\u001b[39m(c\u001b[38;5;241m.\u001b[39mencode(encoding) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m _data) \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;28;01melse\u001b[39;00m _data,\n\u001b[1;32m    513\u001b[0m )\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res:\n\u001b[0;32m--> 515\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _to_error(res)\n",
      "\u001b[0;31mHdfsError\u001b[0m: /corona_data/sido_area_tmp.csv for client 127.0.0.1 already exists\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:388)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2819)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2713)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:830)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:504)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:3203)\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/corona_data/sido_area.csv\", encoding=\"CP949\") as reader, client.write(\"/corona_data/sido_area_tmp.csv\") as writer :\n",
    "    for line in reader: # 읽어와서\n",
    "        writer.write(line.encode(\"CP949\")) # 원래 encoding 방식을 유지 시켜야함, 바로쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66357c92-fbcd-402f-8587-06e10ed6753f",
   "metadata": {},
   "source": [
    "### 인구 사회 데이터 DW에 저장\n",
    "- 인구, 면적, 다중이용 시설 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a45228",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "HdfsError",
     "evalue": "Remote path '/corona_data/tmp/corona_data' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHdfsError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 폴더 전송 : 폴더 내에 있는 파일을 hdfs 특정 디렉터리 모두 복수\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 해당 모듈은 디렉터리와 파일부터 생성하기 쓰기 진행\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 프로그램으로 파일 한줄씩 일어와서 바로 hdfs파일에 쓰기\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# client.upload(data, source)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/corona_data/tmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/corona_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdfs/client.py:599\u001b[0m, in \u001b[0;36mClient.upload\u001b[0;34m(self, hdfs_path, local_path, n_threads, temp_dir, chunk_size, progress, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_name \u001b[38;5;129;01min\u001b[39;00m suffixes:\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HdfsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemote path \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m'\u001b[39m, hdfs_path)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m   temp_path \u001b[38;5;241m=\u001b[39m hdfs_path\n",
      "\u001b[0;31mHdfsError\u001b[0m: Remote path '/corona_data/tmp/corona_data' already exists."
     ]
    }
   ],
   "source": [
    "# 폴더 전송 : 폴더 내에 있는 파일을 hdfs 특정 디렉터리 모두 복수\n",
    "# 해당 모듈은 디렉터리와 파일부터 생성하기 쓰기 진행\n",
    "# 프로그램으로 파일 한줄씩 일어와서 바로 hdfs파일에 쓰기\n",
    "# client.upload(data, source)\n",
    "client.upload(\"/corona_data/tmp\", \"data/corona_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925af9e",
   "metadata": {},
   "source": [
    "## hdfs에 수정하기\n",
    "- ***data 추가***이므로 data 형식과 encoding방식은 기존 파일과 동일하게 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f64f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.write(\"/rdd/score.txt\", \"최연성 장고 100\".encode(\"UTF-8\"), append = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2901c9e3-c309-4d04-9ee5-175d3fcb6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수 스파크 50\n",
      "홍길동 스파크 80\n",
      "임꺽정 스파크 60\n",
      "임요환 텐서플로우 100\n",
      "홍진호 텐서플로우 22\n",
      "홍진호 텐서플로우 22\n",
      "이윤열 텐서플로우 90\n",
      "최연성 장고 100최연성 장고 100최연성 장고 100최연성 장고 100\n"
     ]
    }
   ],
   "source": [
    "# 수정도니 파일 읽어와서 확인\n",
    "# reader = client.read(\"/rdd/score.txt\")와 같은 동작이므로 reader는 객체변수\n",
    "with client.read(\"/rdd/score.txt\") as reader :\n",
    "    score = reader.read()\n",
    "score_data = bytes.decode(score)\n",
    "print(score_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb095c70",
   "metadata": {},
   "source": [
    "## hdfs 권한 수정\n",
    "- 리눅스 명령어(chmod)\n",
    "- InsecureClient 클래스의 set_permission('권한 변경할 파일(폴더 포함)', \"권한문자\")\n",
    "- 권한문자 : 10진수 권한\n",
    "    - ex. 777 : rwxrwxrwx -> 모든 user가 읽기/쓰기/실행 권한을 갖는다\n",
    "    - tip. 777권한은 temp 폴더 등이 갖는 권한이고 공격대상이 될 수 있는 권한이므로 부여 시 주의 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9826da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_permission(\"/corona_data/tmp\", \"777\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1672dc",
   "metadata": {},
   "source": [
    "## hdfs 삭제\n",
    "- InsecureClient 클래스의 delete('삭제할 파일(경로포함)')\n",
    "- 삭제가 정상적으로 진행되면 True 반환\n",
    "- False가 반환된 경우 대부분 파일명 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8cd2e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete(\"/corona_data/tmp/sido_area.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cf822-20d1-4294-948a-a511c25b1538",
   "metadata": {},
   "source": [
    "## 실습 DataPipeline\n",
    "- DataWarehouse\n",
    "    - 현재 실행 중인 ubuntu server의 HDD -> hadoop의 FS로 변경된 공간을 사용 예정\n",
    "        - hadoop 설치\n",
    "        - hdfs 구성(format 등)\n",
    "    - Extract 과정 거쳐서 hdfs에 데이터 저장됨\n",
    "        1. corona 발생현황(일간 데이터) : api 수집\n",
    "        2. corona vaccine 접종현황(일간 데이터) : 파일데이터에서 특정일에 대한 데이터 json형식으로 변환하여 수집\n",
    "        3. 인구 사회 데이터 : 파일 데이터(변환 없이 사용)\n",
    "- Transformation\n",
    "    - HDFS에서 데이터 load해와서 spark 모듈이용 transformation 진행\n",
    "    - DataWarehouse의 데이터보다 정형화된 데이터로 transform\n",
    "- DataMart Load\n",
    "    - transformation 진행된 data를 mysql db에 저장(적재)\n",
    "- Transformation\n",
    "    - DM에서 데이터 load해와서 spark 모듈 이용 transformation 진행\n",
    "    - DM의 데이터보다 정형화되고 논리적 의미를 포함하는 데이터로 transform\n",
    "- 운영DB에 load\n",
    "    - transformation 진행된 data를 mysql db에 저장(적재)\n",
    "    - 운영DB에 적재되는 데이터는 서비스와 연결됨\n",
    "    - 정형화되고 논리적 의미를 포함해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63d843",
   "metadata": {},
   "source": [
    "## REST_API로 데이터를 호출해 HDFS에 저장\n",
    "1. 데이터 신청\n",
    "2. site에서 데이터 수집을 위한 url 제공\n",
    "3. 가이드하고 잇는 방식(get/post)으로 데이터 요청 신행\n",
    "    - header와 params 를 요구\n",
    "        - 생성해서 요청시마다 사용\n",
    "        - params에 service key를 포함시켜 구성\n",
    "4. 요청된 데이터가 프로그램 변수에 저장되면 이 데이터를 정리해서 저장\n",
    "5. 아래의 함수 executeRestApi() 요청하고 데이터 받아 변수 저장하고 함수를 호출한 곳에 데이터 반환(json형태의 text를 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f6aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 요청에 필요한 함수 인수 받아서\n",
    "# 데이터 요청하고 전송된 데이터를 반환하는 함수\n",
    "# 데이터 요청이 실패했을 경우 예외 발생시킴\n",
    "# log 구성해서 예외 발생 시 log에 기록되도록 진행\n",
    "def executeRestApi(method, url, headers, params):  \n",
    "    # params, headers는 dict로 구성되어야함\n",
    "    # raise Exception('응답코드 : 500')  # 예외 테스트\n",
    "    # err_num = 10/0 # 예외 테스트\n",
    "    if method == \"get\": # header가 필요없음 - 파라미터로 사용해야 된다면 보통 빈 {} 디렉터리로\n",
    "        res = requests.get(url, params=params, headers=headers)\n",
    "    else:\n",
    "        res = requests.post(url, data=params, headers=headers)\n",
    "\n",
    "    if res == None or res.status_code != 200:\n",
    "        raise Exception('응답코드 : ' + str(res.status_code))\n",
    "       \n",
    "    return res.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3de26",
   "metadata": {},
   "source": [
    "### 기준일자 함수\n",
    "- 요청의 data의 기준이 되는 yyyy-mm-dd 형식의 날짜 문자열을 생성하는 함수\n",
    "- 오늘로부터 며칠 전 데이터를 요청할 날짜 생성\n",
    "    - ex. 어제 date : 오늘부터 1일전\n",
    "    - ex. 1년 전 data : 오늘부터 365일 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacf8900-5437-4eb0-8c41-57b7effec845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 1, 21, 5, 44, 21, 123706)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.now() - dt.timedelta(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ba1811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-21'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2025-01-20'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2025-01-21'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오늘로부터 며칠 전인지 날짜를 전달 받아서 그날짜부터 생성\n",
    "def cal_std_day(before_day):   \n",
    "    x = dt.datetime.now() - dt.timedelta(before_day)\n",
    "    year = x.year\n",
    "    month = x.month if x.month >= 10 else '0'+ str(x.month)\n",
    "    day = x.day if x.day >= 10 else '0'+ str(x.day)\n",
    "    return str(year)+\"-\"+str(month)+\"-\"+str(day)\n",
    "cal_std_day(365*3)\n",
    "cal_std_day(0)\n",
    "cal_std_day(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496c812",
   "metadata": {},
   "source": [
    "### log 기록\n",
    "\n",
    "#### logger\n",
    "- log 기록하는 프로그램\n",
    "- log : 프로그램을 실행하면서 나타나는 일련의 사건\n",
    "(error, event 등 물리적으로 발생하는 내용이나 네트워크 송수신중 발생하는 많은 내용)\n",
    "- 파이썬 패키지 logging 이용\n",
    "-\n",
    "- log는 외부 연결 시 오류 관련 확인을 위해서 사용자 정의를 기록해야함\n",
    "- restApi는 외부 서버 : log 기록 필요성 있음\n",
    "- 사용자 정의 log 생성\n",
    "    1. 로그 기록/저장할 디렉터리 필요\n",
    "    2. 로그 관련 패키지 import\n",
    "    3. 모듈 활용 객체 (== logger)생성 (logging.getLogger('로거 이름')\n",
    "    4. 로그 파일(을 컨트롤하는) 핸들러 생성 (logging.FileHandler('로그파일명.log'))\n",
    "    5. 로그 파일 핸들러를 로거에 추가(로거와 로그 파일을 연결) : logger.addHandler(로그 파일 핸들러 객체명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba9ddc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83557b42-0120-4cd2-8a49-756af1eeca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_logger = logging.getLogger(\"corona_api\")\n",
    "f_handler = logging.FileHandler(\"./log/rest_api/\"+cal_std_day(0)+\".log\")\n",
    "co_logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e7b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 문자열로 찍을 수도 있음\n",
    "# json양식으로 log를 저장하면 다음에 읽어와서 처리하기도 편하다.\n",
    "# 강제 error 발생시켜서 log 기록 확인\n",
    "# 실제 프로그램에서는 예외 또는 에러가 발생할 때 기록을 위한 logger error 발생\n",
    "co_logger.error(\"corona_patient_\"+cal_std_day(0)+\".json 다운로드 실패\")\n",
    "# 발생된 에러의 log는 내가 만든 /root/note/log/rest_api 디렉터리 log 파일에서 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dda89",
   "metadata": {},
   "source": [
    "### api 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ce26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://apis.data.go.kr/1352000/ODMS_COVID_04/callCovid04Api\"\n",
    "service_key = \"ry3wiibrfwQzUSJCd7jeqtPqKmdasnJANipYjN3PWE6QgWbq9R+s1oKOofHF3go52uYT9jX7HCvCu3W0Yk8reA==\"\n",
    "# 요청하여 응답받은 rest_api data를 hdfs에 저장할 dir\n",
    "file_dir = \"/corona_data/patient/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bca08-e96f-4d1f-afbb-c58f0e754f84",
   "metadata": {},
   "source": [
    "- 기본함수\n",
    "    - executeRestApi(method, url, headers, params)\n",
    "        - 대부분의 요청에 적용되는 함수\n",
    "    - params는 여러 data를 설정해야함\n",
    "        - 파라미터 생성함수 : create_param(std_day)\n",
    "            - std_day : 날짜가 아닌 오늘부터 얼마나 이전 데이터를 요청할 것인지에 대한 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c095c0c2-d7b5-42aa-bea1-f476cc5d438a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serviceKey': 'ry3wiibrfwQzUSJCd7jeqtPqKmdasnJANipYjN3PWE6QgWbq9R+s1oKOofHF3go52uYT9jX7HCvCu3W0Yk8reA==',\n",
       " 'pageNo': 1,\n",
       " 'numOfRows': '500',\n",
       " 'apiType': 'JSON',\n",
       " 'std_day': '2024-01-21'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_param(std_day):\n",
    "    return {\n",
    "        \"serviceKey\":service_key,\n",
    "        \"pageNo\":1,\n",
    "        \"numOfRows\":\"500\",\n",
    "        \"apiType\":\"JSON\",\n",
    "        \"std_day\":cal_std_day(std_day)\n",
    "    }\n",
    "create_param(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce461e8-c8c3-43b7-b251-fa41a80aeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = create_param(365*3)\n",
    "# log 기록할 내용 결정(개발자가 결정)\n",
    "# json형식(dict)으로 log 기록하면 분석이 쉬워짐\n",
    "log_dic={\n",
    "    \"is_success\":\"Fail\",\n",
    "    \"type\":\"corona_patient\",\n",
    "    \"std_day\":params[\"std_day\"],\n",
    "    \"params\":params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946d54d-4ecb-4277-90b6-fb0d97b88404",
   "metadata": {},
   "source": [
    "- 날짜별 발생현황 파일 요청\n",
    "    - 해당 파일에 날짜를 파일명에 포함시켜서\n",
    "    - 정리없이 hdfs 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd20ddf5-4f41-4d44-814a-0ed50313f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청해서 json 응답을 받고, hdfs에 저장하는 작업\n",
    "try :\n",
    "    res = executeRestApi(\"get\", url, {}, params) # api에 data 요청 후 결과 응답\n",
    "    file_name = \"corona_patient_\"+cal_std_day(365*3)+\".json\" # hdfs에 저장할 파일명 생성\n",
    "    client.write(file_dir+file_name, res, encoding = \"utf-8\") # hdfs에 저장\n",
    "except Exception as e: # 일반적인 python 예외\n",
    "    log_dic[\"err_msg\"] = e.__str__()\n",
    "    log_json = json.dumps(log_dic, ensure_ascii=False) # log json 형태로 기록\n",
    "    co_logger.error(log_json) # logger가 발생시키는 강제 에러 // 예외가 발생하면 로거입장에서도 에러를 발생시켜서 기록을 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cab8f2c6-e036-4d92-872a-20ff44be1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d6ad97-c7df-49a8-bc2f-52aa3675006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-15'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_param(365*3+6)[\"std_day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5234a76-ec0b-43da-8345-6fe74b287a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-21\n",
      "2022-01-20\n",
      "2022-01-19\n",
      "2022-01-18\n",
      "2022-01-17\n",
      "2022-01-16\n"
     ]
    }
   ],
   "source": [
    "for i in range(365*3, 365*3+6) :\n",
    "    params = create_param(i)\n",
    "    print(params[\"std_day\"])\n",
    "    try :\n",
    "        res = executeRestApi(\"get\", url, {}, params) \n",
    "        file_name = \"corona_patient_\"+cal_std_day(i)+\".json\"\n",
    "        client.write(file_dir+file_name, res, encoding = \"utf-8\")\n",
    "    except Exception as e:\n",
    "        log_dic[\"err_msg\"] = e.__str__()\n",
    "        log_json = json.dumps(log_dic, ensure_ascii=False) \n",
    "        co_logger.error(log_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd1caa-5160-4cdc-b801-3ca2dd803add",
   "metadata": {},
   "source": [
    "- 2022-01-13~2022-01-18 코로나 발생 현황 data를 hdfs에 json 형식으로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34044be-654e-4273-a969-9f092a719681",
   "metadata": {},
   "source": [
    "## corona_vaccine 접종 현황 data\n",
    "- 파일로 제공\n",
    "- 파일 data 읽어서 json 형식으로 변경한 후에 hdfs에 저장\n",
    "- 필요 data 추출 후 정리 형식 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb185e73-c745-4fff-9f4e-99c4163f02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463ee51f-b43c-448f-884e-beb72ed6f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido</th>\n",
       "      <th>firstCnt</th>\n",
       "      <th>secondCnt</th>\n",
       "      <th>totalFirstCnt</th>\n",
       "      <th>totalSecondCnt</th>\n",
       "      <th>accumulatedFirstCnt</th>\n",
       "      <th>accumulatedSecondCnt</th>\n",
       "      <th>id</th>\n",
       "      <th>thirdCnt</th>\n",
       "      <th>totalThirdCnt</th>\n",
       "      <th>accumulatedThirdCnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-09 00:00:00</th>\n",
       "      <td>제주특별자치도</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>591064</td>\n",
       "      <td>585442.0</td>\n",
       "      <td>591058</td>\n",
       "      <td>585437.0</td>\n",
       "      <td>10176</td>\n",
       "      <td>38.0</td>\n",
       "      <td>439144.0</td>\n",
       "      <td>439106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sido  firstCnt  secondCnt  totalFirstCnt  \\\n",
       "baseDate                                                           \n",
       "2022-11-09 00:00:00  제주특별자치도       6.0        5.0         591064   \n",
       "\n",
       "                     totalSecondCnt  accumulatedFirstCnt  \\\n",
       "baseDate                                                   \n",
       "2022-11-09 00:00:00        585442.0               591058   \n",
       "\n",
       "                     accumulatedSecondCnt     id  thirdCnt  totalThirdCnt  \\\n",
       "baseDate                                                                    \n",
       "2022-11-09 00:00:00              585437.0  10176      38.0       439144.0   \n",
       "\n",
       "                     accumulatedThirdCnt  \n",
       "baseDate                                  \n",
       "2022-11-09 00:00:00             439106.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = pd.read_csv(\"./data/corona_data/sido_population.csv\", encoding=\"cp949\")\n",
    "\n",
    "vac_v1 = pd.read_csv(\"./data/corona_data/Covid19Vaccine.csv\", index_col=0)\n",
    "vac_v1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03b62d",
   "metadata": {},
   "source": [
    "- 백신 데이터 광역시도명이 기 수집한 데이터의 광역시도명과 다르기 때문에 백신데이터를 변경 후 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b8cbd78-1fca-4895-8c11-a0f955431979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseDate\n",
       "2022-11-09 00:00:00    제주특별자치도\n",
       "2022-11-09 00:00:00         전국\n",
       "2022-11-09 00:00:00      서울특별시\n",
       "2022-11-09 00:00:00      부산광역시\n",
       "2022-11-09 00:00:00      대구광역시\n",
       "                        ...   \n",
       "2021-03-11 00:00:00       경상북도\n",
       "2021-03-11 00:00:00       경상남도\n",
       "2021-03-11 00:00:00    제주특별자치도\n",
       "2021-03-11 00:00:00         전국\n",
       "2021-03-11 00:00:00        강원도\n",
       "Name: sido, Length: 10158, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sido                            전국\n",
       "firstCnt                     175.0\n",
       "secondCnt                    224.0\n",
       "totalFirstCnt             45123225\n",
       "totalSecondCnt          44693321.0\n",
       "accumulatedFirstCnt       45123050\n",
       "accumulatedSecondCnt    44693097.0\n",
       "id                           10159\n",
       "thirdCnt                    1678.0\n",
       "totalThirdCnt           33673146.0\n",
       "accumulatedThirdCnt     33671468.0\n",
       "Name: 2022-11-09 00:00:00, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac_v1[\"sido\"]\n",
    "vac_v1.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaa536d8-d47c-46bc-b078-d32b1a6afc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseDate\n",
       "2022-11-09 00:00:00    제주특별자치도\n",
       "2022-11-09 00:00:00         전국\n",
       "2022-11-09 00:00:00      서울특별시\n",
       "2022-11-09 00:00:00      부산광역시\n",
       "2022-11-09 00:00:00      대구광역시\n",
       "2022-11-09 00:00:00      광주광역시\n",
       "2022-11-09 00:00:00      인천광역시\n",
       "2022-11-09 00:00:00      대전광역시\n",
       "2022-11-09 00:00:00        경기도\n",
       "2022-11-09 00:00:00    세종특별자치시\n",
       "2022-11-09 00:00:00       경상남도\n",
       "2022-11-09 00:00:00       경상북도\n",
       "2022-11-09 00:00:00       전라남도\n",
       "2022-11-09 00:00:00       전라북도\n",
       "2022-11-09 00:00:00       충청남도\n",
       "2022-11-09 00:00:00       충청북도\n",
       "2022-11-09 00:00:00        강원도\n",
       "2022-11-09 00:00:00      울산광역시\n",
       "2021-04-26 00:00:00         기타\n",
       "Name: sido, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 데이터 추출 : 중복 없이 추출\n",
    "vac_v1[[\"sido\"]].drop_duplicates()[\"sido\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb02c77d-b710-4e82-b0c5-f6c2091e64eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['강원도', '경기도', '경상남도', '경상북도', '광주광역시', '대구광역시', '대전광역시', '부산광역시', '서울특별시', '세종특별자치시', '울산광역시', '인천광역시', '전국', '전라남도', '전라북도', '제주특별자치도', '충청남도', '충청북도']\n"
     ]
    }
   ],
   "source": [
    "before = [sido for sido in vac_v1[[\"sido\"]].drop_duplicates()[\"sido\"]]\n",
    "before.sort()\n",
    "before.remove(\"기타\")\n",
    "print(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9b3f2b-4a19-4898-8576-4fc3e2880cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     전국\n",
       "1     서울\n",
       "2     부산\n",
       "3     대구\n",
       "4     인천\n",
       "5     광주\n",
       "6     대전\n",
       "7     울산\n",
       "8     세종\n",
       "9     경기\n",
       "10    강원\n",
       "11    충북\n",
       "12    충남\n",
       "13    전북\n",
       "14    전남\n",
       "15    경북\n",
       "16    경남\n",
       "17    제주\n",
       "Name: loc, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop[\"loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e5ca91-ddb5-4e2a-afe5-13242df2e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['강원', '경기', '경남', '경북', '광주', '대구', '대전', '부산', '서울', '세종', '울산', '인천', '전국', '전남', '전북', '제주', '충남', '충북']\n"
     ]
    }
   ],
   "source": [
    "after = [sido for sido in pop[\"loc\"]]\n",
    "after.sort()\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8c86f08-62cd-42e3-a59c-cbb62c5da29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseDate\n",
       "2022-11-09 00:00:00    제주\n",
       "2022-11-09 00:00:00    전국\n",
       "2022-11-09 00:00:00    서울\n",
       "2022-11-09 00:00:00    부산\n",
       "2022-11-09 00:00:00    대구\n",
       "                       ..\n",
       "2021-03-11 00:00:00    경북\n",
       "2021-03-11 00:00:00    경남\n",
       "2021-03-11 00:00:00    제주\n",
       "2021-03-11 00:00:00    전국\n",
       "2021-03-11 00:00:00    강원\n",
       "Name: sido, Length: 10158, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac_v1[\"sido\"].replace(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e34a99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(after)) :\n",
    "    vac_v1[\"sido\"] = vac_v1[\"sido\"].replace(before[i], after[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f354d1-000e-4716-bd0d-e9de09bb9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, 2022-01-18 00:00:00 to 2022-01-18 00:00:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   sido                  18 non-null     object \n",
      " 1   firstCnt              18 non-null     float64\n",
      " 2   secondCnt             18 non-null     float64\n",
      " 3   totalFirstCnt         18 non-null     int64  \n",
      " 4   totalSecondCnt        18 non-null     float64\n",
      " 5   accumulatedFirstCnt   18 non-null     int64  \n",
      " 6   accumulatedSecondCnt  18 non-null     float64\n",
      " 7   id                    18 non-null     int64  \n",
      " 8   thirdCnt              18 non-null     float64\n",
      " 9   totalThirdCnt         18 non-null     float64\n",
      " 10  accumulatedThirdCnt   18 non-null     float64\n",
      "dtypes: float64(7), int64(3), object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2022-01-18에 해당하는 data를 vac_v1에서 추출\n",
    "# \"2022-11-09 00:00:00\"\n",
    "finVac = vac_v1.loc[vac_v1.index.str.contains(\"2022-01-18\")]\n",
    "finVac.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c02c1-af97-4cbd-bc25-d2e3a88659c9",
   "metadata": {},
   "source": [
    "## Json 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb4e89e5-5baf-4ab8-93eb-8f8891233dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sido                           대구\n",
       "firstCnt                    893.0\n",
       "secondCnt                  4524.0\n",
       "totalFirstCnt             1997407\n",
       "totalSecondCnt          1945813.0\n",
       "accumulatedFirstCnt       1996514\n",
       "accumulatedSecondCnt    1941289.0\n",
       "id                           5644\n",
       "thirdCnt                  15716.0\n",
       "totalThirdCnt            978794.0\n",
       "accumulatedThirdCnt      963078.0\n",
       "Name: 2022-01-18 00:00:00, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레코드 추출 - iloc[]\n",
    "finVac.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acaf5d7b-e8fb-4cc0-9b42-6034684c911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs에 저장할 데이터\n",
    "cols = [\"loc\", \"v1\", \"v2\", \"v3\"]\n",
    "data = []\n",
    "for idx in range(0, len(finVac.index)):\n",
    "    tuple_t = []\n",
    "    tmp = finVac.iloc[idx]\n",
    "    tuple_t.append(str(tmp.sido))\n",
    "    tuple_t.append(str(tmp.totalFirstCnt))\n",
    "    tuple_t.append(str(tmp.totalSecondCnt))\n",
    "    tuple_t.append(str(tmp.totalThirdCnt))\n",
    "    # print(tuple_t)\n",
    "    data.append(dict(zip(cols, tuple_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c48bf1c-5c6f-41ec-99aa-4aea23e2c563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loc': '광주', 'v1': '1247764', 'v2': '1220758.0', 'v3': '682394.0'},\n",
       " {'loc': '울산', 'v1': '956895', 'v2': '933311.0', 'v3': '476692.0'},\n",
       " {'loc': '인천', 'v1': '2532911', 'v2': '2484196.0', 'v3': '1330273.0'},\n",
       " {'loc': '대전', 'v1': '1231435', 'v2': '1203724.0', 'v3': '628469.0'},\n",
       " {'loc': '대구', 'v1': '1997407', 'v2': '1945813.0', 'v3': '978794.0'},\n",
       " {'loc': '부산', 'v1': '2849093', 'v2': '2788089.0', 'v3': '1554554.0'},\n",
       " {'loc': '서울', 'v1': '8239400', 'v2': '8090244.0', 'v3': '4304485.0'},\n",
       " {'loc': '전국', 'v1': '44505276', 'v2': '43582128.0', 'v3': '23741205.0'},\n",
       " {'loc': '세종', 'v1': '290455', 'v2': '282507.0', 'v3': '138100.0'},\n",
       " {'loc': '경기', 'v1': '11652853', 'v2': '11414202.0', 'v3': '5970505.0'},\n",
       " {'loc': '제주', 'v1': '580579', 'v2': '566811.0', 'v3': '295807.0'},\n",
       " {'loc': '경남', 'v1': '2848083', 'v2': '2783896.0', 'v3': '1517240.0'},\n",
       " {'loc': '경북', 'v1': '2260963', 'v2': '2202814.0', 'v3': '1247047.0'},\n",
       " {'loc': '전남', 'v1': '1632045', 'v2': '1602479.0', 'v3': '1031459.0'},\n",
       " {'loc': '전북', 'v1': '1574779', 'v2': '1547262.0', 'v3': '958100.0'},\n",
       " {'loc': '충남', 'v1': '1870124', 'v2': '1830143.0', 'v3': '1048429.0'},\n",
       " {'loc': '충북', 'v1': '1408620', 'v2': '1379378.0', 'v3': '783588.0'},\n",
       " {'loc': '강원', 'v1': '1331870', 'v2': '1306501.0', 'v3': '795269.0'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3df8ceb6-0cde-4baf-b5b6-e8bdf8edc350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'desc': '지역별 코로나 예방접종 인구 현황',\n",
       "  'cols': {'loc': '지역', 'v1': '1차 접종 누적', 'v2': '2차 접종 누적', 'v3': '3차 접종 누적'},\n",
       "  'stdDay': '2022-01-21'},\n",
       " 'data': [{'loc': '광주', 'v1': '1247764', 'v2': '1220758.0', 'v3': '682394.0'},\n",
       "  {'loc': '울산', 'v1': '956895', 'v2': '933311.0', 'v3': '476692.0'},\n",
       "  {'loc': '인천', 'v1': '2532911', 'v2': '2484196.0', 'v3': '1330273.0'},\n",
       "  {'loc': '대전', 'v1': '1231435', 'v2': '1203724.0', 'v3': '628469.0'},\n",
       "  {'loc': '대구', 'v1': '1997407', 'v2': '1945813.0', 'v3': '978794.0'},\n",
       "  {'loc': '부산', 'v1': '2849093', 'v2': '2788089.0', 'v3': '1554554.0'},\n",
       "  {'loc': '서울', 'v1': '8239400', 'v2': '8090244.0', 'v3': '4304485.0'},\n",
       "  {'loc': '전국', 'v1': '44505276', 'v2': '43582128.0', 'v3': '23741205.0'},\n",
       "  {'loc': '세종', 'v1': '290455', 'v2': '282507.0', 'v3': '138100.0'},\n",
       "  {'loc': '경기', 'v1': '11652853', 'v2': '11414202.0', 'v3': '5970505.0'},\n",
       "  {'loc': '제주', 'v1': '580579', 'v2': '566811.0', 'v3': '295807.0'},\n",
       "  {'loc': '경남', 'v1': '2848083', 'v2': '2783896.0', 'v3': '1517240.0'},\n",
       "  {'loc': '경북', 'v1': '2260963', 'v2': '2202814.0', 'v3': '1247047.0'},\n",
       "  {'loc': '전남', 'v1': '1632045', 'v2': '1602479.0', 'v3': '1031459.0'},\n",
       "  {'loc': '전북', 'v1': '1574779', 'v2': '1547262.0', 'v3': '958100.0'},\n",
       "  {'loc': '충남', 'v1': '1870124', 'v2': '1830143.0', 'v3': '1048429.0'},\n",
       "  {'loc': '충북', 'v1': '1408620', 'v2': '1379378.0', 'v3': '783588.0'},\n",
       "  {'loc': '강원', 'v1': '1331870', 'v2': '1306501.0', 'v3': '795269.0'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 설명하는 메타 데이터\n",
    "res = {\n",
    "    \"meta\" : {\n",
    "        \"desc\":\"지역별 코로나 예방접종 인구 현황\",\n",
    "        \"cols\":{\n",
    "            \"loc\":\"지역\",\n",
    "            \"v1\":\"1차 접종 누적\",\n",
    "            \"v2\":\"2차 접종 누적\",\n",
    "            \"v3\":\"3차 접종 누적\"\n",
    "        },\n",
    "        \"stdDay\":cal_std_day(365*3)\n",
    "    },\n",
    "    \"data\":data\n",
    "}\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46b78cde-7e71-4e62-bc12-2df7fd983e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir_vac = \"/corona_data/vaccine/\"\n",
    "file_name = \"corona_vaccine_\"+cal_std_day(365*3+3)+\".json\"\n",
    "client.write(file_dir_vac+file_name, json.dumps(res, ensure_ascii=False),encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1009e14f-ebc8-492a-be85-c84bd63d777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------------+\n",
      "|                  data|                       meta|\n",
      "+----------------------+---------------------------+\n",
      "|[{광주, 1247764, 12...|{{지역, 1차 접종 누적, 2...|\n",
      "+----------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_dir_vac = \"/corona_data/vaccine/\"\n",
    "file_name = \"corona_vaccine_\"+cal_std_day(365*3+3)+\".json\"\n",
    "vaccine = spark.read.json(file_dir_vac+file_name)\n",
    "vaccine.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "202d7801-079d-4d09-86e2-0aee0f91c178",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/corona_data/Covid19CaccineC2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 파일 읽어오기\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vac_v1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/corona_data/Covid19CaccineC2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/corona_data/Covid19CaccineC2.csv'"
     ]
    }
   ],
   "source": [
    "# 파일 읽어오기\n",
    "vac_v1 = pd.read_csv(\"data/corona_data/Covid19CaccineC2.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec40f82-3574-4dd2-bd23-e3c48d4b4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 코드\n",
    "# hdfs에 저장할 데이터\n",
    "for i in range(365*3, 365*3+6) :\n",
    "    print(cal_std_day(i))\n",
    "    cols = [\"loc\", \"v1\", \"v2\", \"v3\"]\n",
    "    data = []\n",
    "    finVac = vac_v1.loc[vac_v1.index.str.contains(cal_std_day(i))]\n",
    "    for idx in range(0, len(finVac.index)):\n",
    "        tuple_t = []\n",
    "        tmp = finVac.iloc[idx]\n",
    "        tuple_t.append(str(tmp.sido))\n",
    "        tuple_t.append(str(tmp.totalFirstCnt))\n",
    "        tuple_t.append(str(tmp.totalSecondCnt))\n",
    "        tuple_t.append(str(tmp.thirdCnt))\n",
    "        # print(tuple_t)\n",
    "        data.append(dict(zip(cols, tuple_t)))\n",
    "    \n",
    "    # data를 설명하는 메타 데이터\n",
    "    res = {\n",
    "        \"meta\" : {\n",
    "            \"desc\":\"지역별 코로나 예방접종 인구 현황\",\n",
    "            \"cols\":{\n",
    "                \"loc\":\"지역\",\n",
    "                \"v1\":\"1차 접종 누적\",\n",
    "                \"v2\":\"2차 접종 누적\",\n",
    "                \"v3\":\"3차 접종 누적\"\n",
    "            },\n",
    "            \"stdDay\":cal_std_day(i)\n",
    "        },\n",
    "        \"data\":data\n",
    "    }\n",
    "    try :\n",
    "        file_dir_vac = \"/corona_data/vaccine/\"\n",
    "        file_name = \"corona_vaccine_\"+cal_std_day(i)+\".json\"\n",
    "        client.write(file_dir_vac+file_name, json.dumps(res, ensure_ascii=False),encoding=\"utf-8\")\n",
    "    except Exception as e :\n",
    "        log_dic = {\n",
    "            \"type\":\"/corona_data/vaccine/\",\n",
    "            \"err_msg\":e.__str__()\n",
    "        }\n",
    "        log_json = json.dumps(log_dic, ensure_ascii=False)\n",
    "        co_logger.error(log_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00476c81-722d-4345-83e0-b934466ce859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
